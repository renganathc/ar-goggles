{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09c4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apriltag\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f4f2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateUI():\n",
    "\tUIHeight = 1080\n",
    "\tUIWidth = 1900\n",
    "\n",
    "\tUIBG = np.zeros((UIHeight,UIWidth,3),dtype=np.uint8)\n",
    "\n",
    "\tBoxHeight = 1000\n",
    "\tBoxWidth = 400\n",
    "\tGap = 175\n",
    "\n",
    "\tYStart = int((UIHeight-BoxHeight)/2)\n",
    "\n",
    "\tfor i in range(3):\n",
    "\t\tXStart = Gap + i*(BoxWidth+Gap)\n",
    "\n",
    "\t\tBoxTopLeft = (XStart,YStart)\n",
    "\t\tBoxBottomRight = (XStart+BoxWidth , YStart+BoxHeight)\n",
    "\n",
    "\t\tcv2.rectangle(UIBG,BoxTopLeft,BoxBottomRight,(192,242,30),-1)\n",
    "\n",
    "\t\tBoxDims.append((XStart,YStart,BoxWidth,BoxHeight))\n",
    "\treturn UIBG\n",
    "\n",
    "def CalculateUICorners(Tag):\n",
    "\tMarkerTopLeft,MarkerTopRight,MarkerBottomRight,MarkerBottomLeft = Tag.corners[0],Tag.corners[1],Tag.corners[2],Tag.corners[3]\n",
    "\tMarkerCenter = Tag.center\n",
    "\tTopVector = MarkerTopRight - MarkerTopLeft\n",
    "\tLeftVector = MarkerBottomLeft - MarkerTopLeft\n",
    "\tOffsetScale = 2\n",
    "\tUIScale = 2\n",
    "\tUICenter = MarkerCenter+(LeftVector*OffsetScale)\n",
    "\tUIWidth = TopVector*UIScale\n",
    "\tUIHeight = LeftVector*UIScale\n",
    "\tUITopLeft = UICenter-(UIWidth/2)-(UIHeight/2)\n",
    "\tUITopRight = UITopLeft+UIWidth\n",
    "\tUIBottomLeft = UITopLeft+UIHeight\n",
    "\tUIBottomRight = UITopLeft+UIWidth+UIHeight\n",
    "\n",
    "\treturn np.array([UITopLeft,UITopRight,UIBottomRight,UIBottomLeft], dtype=np.float32)\n",
    "\n",
    "def Touch(frame,Matrix,WFrame,HFrame,UIBG):\n",
    "\tFingerOption = -1\n",
    "\tRGB = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\tMpResult = hand.process(RGB)\n",
    "\n",
    "\tif MpResult.multi_hand_landmarks and Matrix is not None:\n",
    "\t\tHandLandmarks = MpResult.multi_hand_landmarks[0]\n",
    "\t\tmpdrawing.draw_landmarks(frame, HandLandmarks, mphands.HAND_CONNECTIONS)\n",
    "\t\tIndexTip = HandLandmarks.landmark[mphands.HandLandmark.INDEX_FINGER_TIP]\n",
    "\t\tThumbTip = HandLandmarks.landmark[mphands.HandLandmark.THUMB_TIP]\n",
    "\t\tIndexPos = (int(IndexTip.x * WFrame),int(IndexTip.y * HFrame))\n",
    "\n",
    "\t\ttry:\n",
    "\t\t\tInvMatrix = np.linalg.inv(Matrix)\n",
    "\t\t\tFingerPosOnUI = cv2.perspectiveTransform(np.array([[IndexPos]], dtype=np.float32), InvMatrix)\n",
    "\t\t\tfx,fy = int(FingerPosOnUI[0][0][0]),int(FingerPosOnUI[0][0][1])\n",
    "\t\t\tcv2.circle(UIBG, (fx, fy), 15, (0, 0, 255), -1)\n",
    "\t\t\tfor i,(bx,by,bw,bh) in enumerate(BoxDims):\n",
    "\t\t\t\tif bx<fx<bx+bw and by<fy<by+bh:\n",
    "\t\t\t\t\tFingerOption = i\n",
    "\t\t\t\t\tbreak\n",
    "\t\texcept np.linalg.LinAlgError:\n",
    "\t\t\tprint(\"LinAlgError!\")\n",
    "\n",
    "\t\tdist = math.hypot(ThumbTip.x - IndexTip.x , ThumbTip.y-IndexTip.y)\n",
    "\t\tIsPinching = dist < 0.05\n",
    "\t\tif FingerOption != -1 and IsPinching:\n",
    "\t\t\tprint(f\"User selected box {FingerOption+1}\")\n",
    "\t\t\t(bx,by,bw,bh) = BoxDims[FingerOption]\n",
    "\t\t\tcv2.rectangle(UIBG, (bx,by), (bx+bw,by+bh), (0,255,0), -1)\n",
    "\n",
    "\treturn UIBG,FingerOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23a60760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1757946449.620699  398612 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1757946449.723279  434797 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 580.65.06), renderer: NVIDIA GeForce RTX 5070 Laptop GPU/PCIe/SSE2\n",
      "W0000 00:00:1757946449.766146  434773 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1757946449.793176  434776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "#Setup\n",
    "\n",
    "BoxDims = []\n",
    "UIBGOriginal = CreateUI()\n",
    "h,w,c = UIBGOriginal.shape\n",
    "options = apriltag.DetectorOptions(families=\"tag16h5\")\n",
    "detector = apriltag.Detector(options)\n",
    "Angle = 0\n",
    "mphands = mp.solutions.hands\n",
    "mpdrawing = mp.solutions.drawing_utils\n",
    "hand = mphands.Hands(min_detection_confidence = 0.7,max_num_hands = 1)\n",
    "\n",
    "KalmanFilters = [cv2.KalmanFilter(4,2) for _ in range(4)]\n",
    "for kf in KalmanFilters:\n",
    "\tkf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "\tkf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "\tkf.processNoiseCov = np.eye(4, dtype=np.float32) * 1e-3\n",
    "\tkf.measurementNoiseCov = np.eye(2, dtype=np.float32) * 1e-2\n",
    "\n",
    "calibrated = False\n",
    "FramesSinceDetection = 0\n",
    "\n",
    "cam = cv2.VideoCapture(0,cv2.CAP_V4L2)\n",
    "cam.set(cv2.CAP_PROP_FRAME_WIDTH, 1080)\n",
    "cam.set(cv2.CAP_PROP_FRAME_HEIGHT, 1900)\n",
    "if not cam.isOpened():\n",
    "\tprint(\"Cannot Open Camera\")\n",
    "\texit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaa32bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated!\n",
      "User selected box 2\n",
      "User selected box 2\n",
      "User selected box 2\n",
      "User selected box 2\n",
      "User selected box 1\n",
      "User selected box 1\n",
      "User selected box 1\n",
      "User selected box 2\n",
      "User selected box 2\n",
      "User selected box 3\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\t\n",
    "\tUIBG = UIBGOriginal.copy()\n",
    "\tsuccess,frame = cam.read()\n",
    "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\tHFrame,WFrame,_ = frame.shape\n",
    "\tFrameArea = HFrame*WFrame\n",
    "\n",
    "\tApriltagResults = detector.detect(gray)\n",
    "\n",
    "\tMatrix = None\n",
    "\n",
    "\tkey = cv2.waitKey(1) & 0xFF\n",
    "\t\n",
    "\tif not calibrated and ApriltagResults:\n",
    "\t\tif key == ord('c'):\n",
    "\t\t\tfor r in ApriltagResults:\n",
    "\t\t\t\tMarkerArea = cv2.contourArea(np.array(r.corners, dtype=np.int32))\n",
    "\t\t\t\tif r.tag_id == 0 and MarkerArea > (FrameArea*0.008):\n",
    "\t\t\t\t\tDestinationPoints = CalculateUICorners(ApriltagResults[0])\n",
    "\n",
    "\t\t\t\t\tfor i,corner in enumerate(DestinationPoints):\n",
    "\t\t\t\t\t\tKalmanFilters[i].statePost = np.array([corner[0], corner[1], 0, 0], dtype=np.float32)\n",
    "\n",
    "\t\t\tcalibrated = True\n",
    "\t\t\tprint(\"Calibrated!\")\n",
    "\t\n",
    "\tif calibrated:\n",
    "\t\tPredictedCorners = np.array([kf.predict()[:2].flatten() for kf in KalmanFilters], dtype=np.float32)\n",
    "\n",
    "\t\tif ApriltagResults:\n",
    "\t\t\tfor r in ApriltagResults:\n",
    "\t\t\t\tMarkerArea = cv2.contourArea(np.array(r.corners, dtype=np.int32))\n",
    "\t\t\t\tif r.tag_id == 0 and MarkerArea > (FrameArea*0.008):\n",
    "\t\t\t\t\tDestinationPoints = CalculateUICorners(ApriltagResults[0])\n",
    "\t\t\t\t\tFramesSinceDetection = 0\n",
    "\t\t\t\t\tfor i,corner in enumerate(DestinationPoints):\n",
    "\t\t\t\t\t\tKalmanFilters[i].correct(corner)\n",
    "\t\telse:\n",
    "\t\t\tFramesSinceDetection += 1\n",
    "\n",
    "\t\tSmoothPoints = np.array([kf.statePost[:2].flatten() for kf in KalmanFilters], dtype=np.float32)\n",
    "\t\t\n",
    "\t\tif FramesSinceDetection <= 3:\n",
    "\t\t\tSourcePoints = np.array([[0,0],[w,0],[w,h],[0,h]], dtype=np.float32)\n",
    "\t\t\tMatrix,_ = cv2.findHomography(SourcePoints,SmoothPoints)\n",
    "\n",
    "\t\t\tUIBG,FingerOption = Touch(frame,Matrix,WFrame,HFrame,UIBG)\n",
    "\n",
    "\t\t\tif Matrix is not None:\n",
    "\t\t\t\tWarpedUI = cv2.warpPerspective(UIBG, Matrix, (WFrame,HFrame))\n",
    "\n",
    "\t\t\t\tmask = np.sum(WarpedUI, axis=2) > 0\n",
    "\t\t\t\tframe[mask] = WarpedUI[mask]\n",
    "\n",
    "\tif not calibrated:\n",
    "\t\t\tcv2.putText(frame, \"Show marker and press 'c' to calibrate\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\t\t\t\n",
    "\tcv2.imshow(\"VideoFeed\",frame)\n",
    "\n",
    "\tif key == ord('q'):\n",
    "\t\tbreak\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
